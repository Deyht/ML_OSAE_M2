{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **IRIS CIANNA**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Deyht/AI_astro_ED_AAIF/blob/main/codes/mlp/CIANNA/iris_colab_notebook.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Link to the CIANNA github repository**\n",
        "https://github.com/Deyht/CIANNA"
      ],
      "metadata": {
        "id": "JfKCrIlDu-E0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CIANNA installation**"
      ],
      "metadata": {
        "id": "vIXMFIFmvYzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Query GPU allocation and properties\n",
        "\n",
        "If nvidia-smi fail, it might indicate that you launched the colab session whithout GPU reservation.  \n",
        "To change the type of reservation go to \"Runtime\"->\"Change runtime type\" and select \"GPU\" as your hardware accelerator."
      ],
      "metadata": {
        "id": "Ke8s2bCZvk1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "nvidia-smi\n",
        "\n",
        "cd /content/\n",
        "\n",
        "git clone https://github.com/NVIDIA/cuda-samples/\n",
        "\n",
        "cd /content/cuda-samples/Samples/1_Utilities/deviceQuery/\n",
        "\n",
        "cmake CMakeLists.txt\n",
        "\n",
        "make SMS=\"50 60 70 80\"\n",
        "\n",
        "./deviceQuery | grep Capability | cut -c50- > ~/cuda_infos.txt\n",
        "./deviceQuery | grep \"CUDA Driver Version / Runtime Version\" | cut -c57- >> ~/cuda_infos.txt\n",
        "\n",
        "cd ~/"
      ],
      "metadata": {
        "id": "AHq06Uwk49Ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c2e8d8a-e701-4d15-984c-6f7b4153ecd6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec 13 09:28:54 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "Cloning into 'cuda-samples'...\n",
            "remote: Enumerating objects: 19507, done.\u001b[K\n",
            "remote: Counting objects: 100% (10080/10080), done.\u001b[K\n",
            "remote: Compressing objects: 100% (746/746), done.\u001b[K\n",
            "remote: Total 19507 (delta 9716), reused 9419 (delta 9334), pack-reused 9427 (from 1)\u001b[K\n",
            "Receiving objects: 100% (19507/19507), 133.56 MiB | 13.90 MiB/s, done.\n",
            "Resolving deltas: 100% (17171/17171), done.\n",
            "Updating files: 100% (4026/4026), done.\n",
            "/usr/local/cuda/bin/nvcc -ccbin g++ -I../../../Common -m64 --threads 0 --std=c++11 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_80,code=compute_80 -o deviceQuery.o -c deviceQuery.cpp\n",
            "/usr/local/cuda/bin/nvcc -ccbin g++ -m64 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_80,code=compute_80 -o deviceQuery deviceQuery.o \n",
            "mkdir -p ../../../bin/x86_64/linux/release\n",
            "cp deviceQuery ../../../bin/x86_64/linux/release\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are granted a GPU that supports high FP16 compute scaling (e.g the Tesla T4), it is advised to change the mixed_precision parameter in the prediction to \"FP16C_FP32A\".  \n",
        "See the detail description on mixed precision support with CIANNA on the [Systeme Requirements](https://github.com/Deyht/CIANNA/wiki/1\\)-System-Requirements) wiki page."
      ],
      "metadata": {
        "id": "tZ-lmHiRBFwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clone CIANNA git repository"
      ],
      "metadata": {
        "id": "A1SJ6-x8vqsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/\n",
        "\n",
        "git clone https://github.com/Deyht/CIANNA\n",
        "\n",
        "cd CIANNA"
      ],
      "metadata": {
        "id": "_uptvrov55YL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c74a8f7-d03c-4dfa-bcca-d4942885196a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CIANNA'...\n",
            "remote: Enumerating objects: 2120, done.\u001b[K\n",
            "remote: Counting objects: 100% (549/549), done.\u001b[K\n",
            "remote: Compressing objects: 100% (183/183), done.\u001b[K\n",
            "remote: Total 2120 (delta 389), reused 518 (delta 364), pack-reused 1571 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2120/2120), 62.13 MiB | 15.24 MiB/s, done.\n",
            "Resolving deltas: 100% (1571/1571), done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compiling CIANNA for the allocated GPU generation\n",
        "\n",
        "There is no guaranteed forward or backward compatibility between Nvidia GPU generation, and some capabilities are generation specific. For these reasons, CIANNA must be provided the platform GPU generation at compile time.\n",
        "The following cell will automatically update all the necessary files based on the detected GPU, and compile CIANNA."
      ],
      "metadata": {
        "id": "JYGPC3OUv0td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/CIANNA\n",
        "\n",
        "mult=\"10\"\n",
        "cat ~/cuda_infos.txt\n",
        "comp_cap=\"$(sed '1!d' ~/cuda_infos.txt)\"\n",
        "cuda_vers=\"$(sed '2!d' ~/cuda_infos.txt)\"\n",
        "\n",
        "lim=\"11.1\"\n",
        "old_arg=$(awk '{if ($1 < $2) print \"-D CUDA_OLD\";}' <<<\"${cuda_vers} ${lim}\")\n",
        "\n",
        "sm_val=$(awk '{print $1*$2}' <<<\"${mult} ${comp_cap}\")\n",
        "\n",
        "gen_val=$(awk '{if ($1 >= 80) print \"-D GEN_AMPERE\"; else if($1 >= 70) print \"-D GEN_VOLTA\";}' <<<\"${sm_val}\")\n",
        "\n",
        "sed -i \"s/.*arch=sm.*/\\\\t\\tcuda_arg=\\\"\\$cuda_arg -D CUDA -D comp_CUDA -lcublas -lcudart -arch=sm_$sm_val $old_arg $gen_val\\\"/g\" compile.cp\n",
        "sed -i \"s/\\/cuda-[0-9][0-9].[0-9]/\\/cuda-$cuda_vers/g\" compile.cp\n",
        "sed -i \"s/\\/cuda-[0-9][0-9].[0-9]/\\/cuda-$cuda_vers/g\" src/python_module_setup.py\n",
        "\n",
        "./compile.cp CUDA PY_INTERF\n",
        "\n",
        "mv src/build/lib.linux-x86_64-* src/build/lib.linux-x86_64"
      ],
      "metadata": {
        "id": "HGJUvmWW7YE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb542c1-fd30-432d-9f20-935572945c0e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.5\n",
            "12.2\n",
            "USE_CUDA\n",
            "BUILD PY_INTERF\n",
            "#####  End of CUDA compilation  #####\n",
            "#####  End of main program compilation  #####\n",
            "#####  End of link edition and executable creation  #####\n",
            "USE_CUDA\n",
            "running build\n",
            "running build_ext\n",
            "building 'CIANNA' extension\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -DMAX_LAYERS_NB=200 -DMAX_NETWORKS_NB=10 -DCUDA=1 -DCUDA_THREADS_PER_BLOCKS=256 -DNone -I/usr/local/cuda-12.2/include -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I/usr/include/python3.10 -c python_module.c -o build/temp.linux-x86_64-cpython-310/python_module.o\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "x86_64-linux-gnu-gcc -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/python_module.o conv_layer.o dense_layer.o pool_layer.o norm_layer.o lrn_layer.o activ_functions.o initializers.o vars.o auxil.o naiv/naiv_dense_layer.o naiv/naiv_conv_layer.o naiv/naiv_pool_layer.o naiv/naiv_norm_layer.o cuda/cuda_main.o cuda/cuda_conv_layer.o cuda/cuda_dense_layer.o cuda/cuda_pool_layer.o cuda/cuda_norm_layer.o cuda/cuda_lrn_layer.o cuda/cuda_activ_functions.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-310/CIANNA.cpython-310-x86_64-linux-gnu.so \"-O3 -std=c99 --disable-gil\" -L/usr/local/cuda-12.2/lib64 -lcudart -lcublas -lcurand\n",
            "#####  End of Python3 interface build  #####\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**IMPORTANT NOTE**   \n",
        "CIANNA is mainly used in a script fashion and was not designed to run in notebooks. Every cell code that directly invokes CIANNA functions must be run as a script to avoid possible errors.  \n",
        "To do so, the cell must have the following structure.\n",
        "\n",
        "```\n",
        "%%shell\n",
        "\n",
        "cd /content/CIANNA\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "[... your python code ...]\n",
        "\n",
        "EOF\n",
        "```\n",
        "\n",
        "This syntax allows one to easily edit python code in the notebook while running the cell as a script. Note that all the notebook variables can not be accessed by the cell in this context.\n"
      ],
      "metadata": {
        "id": "vbnBhbIL8wv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/\n",
        "\n",
        "#Manually upload the directory to github if not yet opened\n",
        "git clone https://github.com/Deyht/AI_astro_ED_AAIF"
      ],
      "metadata": {
        "id": "mjcrByRgYof3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b452969d-bda9-4960-dc2c-252095ff8832"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AI_astro_ED_AAIF'...\n",
            "remote: Enumerating objects: 126, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 126 (delta 36), reused 56 (delta 26), pack-reused 49 (from 1)\u001b[K\n",
            "Receiving objects: 100% (126/126), 9.69 MiB | 4.80 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTUQpT91-Avc",
        "outputId": "c9314992-f511-4208-dbe9-84744e5f689e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                   ..:^~!?JY5PB~                                                                                             \n",
            "           J5PGB#&&&&&#BGP55YY#&#!                                                                                           \n",
            "           &GGB##&&&@@@@@&#PJ?B#&B                                                                                           \n",
            "          .&#&@@@@@@@@@@@@@@@B##&G                                                                                           \n",
            "        ^G@@@@BJ^.   .~?P&@@@@@&&G                                                                                           \n",
            "      &&@@@B^   :!???^^..:7&@@@@&G      .~~~         :~~:         ~~~^        ~~~    ~~~^        ~~~         ^~~.            \n",
            "    .B@@@&^  !#@@@@@@@@&?^~J&@@@@B ^    !@@@.       :@@@@^       .@@@@G      .@@@:  .@@@@P      .@@@:       ~@@@@.           \n",
            "   .&@@@#  .J@@@#GP55PB&@&JJ5@@@@B ^G   !@@@.       &@@@@@.      .@@@@@&:     @@@:  .@@@@@&:    .@@@.      :@@@@@&           \n",
            "   &@@@@.  ?@@&Y?JJJJJJJP@5JY@@@@B ^@:  !@@@       #@@PY@@&      .@@@P@@@7    @@@:  .@@@P@@@7   .@@@.      &@@JG@@B          \n",
            "  :@@@@#  .@@@YJJJJJJJJJJGY?#@@@@B 5@!  !@@@      P@@#  G@@B     .@@@.:&@@G   @@@:  .@@@.:&@@P  .@@@.     #@@P  &@@5         \n",
            "  ~@Y&@#  .@@@P?JJJJJJJJJ?J#@@@@@G.@@~  !@@@     ?@@@:  .&@@5    .@@@.  G@@&. @@@:  .@@@.  G@@&. @@@.    P@@&.  :@@@7        \n",
            "  .@:#@@.  B@@@P5JJJJJJJ5B@@@@@@&#&@&   !@@@    ~@@@@@@@@@@@@7   .@@@.   ?@@@J@@@:  .@@@.   ?@@@J@@@.   ?@@@@@@@@@@@@^       \n",
            "   5^7@@#   G@@@&&&###&@@@@@@&&B@@@@^   !@@@   .@@@Y??????J@@@^  .@@@.    :&@@@@@:  .@@@.    :&@@@@@.  ~@@@J??????5@@@.      \n",
            "    : B@@&~  ^B@@@@@@@@@@&GPYJ#@@@@^    !@@@. .@@@J        7@@@: .@@@:      G@@@@:  .@@@.      G@@@@: :@@@!        5@@&.     \n",
            "       G@@@&?. .~5B&GJ7^:::7B@@@@&      .YJ?  ^YJ7          !JY~  ?JJ        !YJJ    JJJ        !YJJ  !YY!          ?JY^     \n",
            "        7&@@@@&G?~^^~!Y5G&@@@@@&&G                                                                                           \n",
            "          ?@@@@@@@@@@@@@@@&#GY##&G                                                                                           \n",
            "           &PB&@@@@&&##BGP5J??B#&B                                                                                           \n",
            "           Y55PGB##&&&#BGPP55Y#&#!                                                                                           \n",
            "                  ...:^~!?JY5PB~                                                                                             \n",
            "\n",
            "############################################################\n",
            "CIANNA V-1.0.0.0 Release build (07/2024), by D.Cornu\n",
            "############################################################\n",
            "\n",
            "Network (id: 0) initialized with : \n",
            "Input dimensions: 4x1x1x1 \n",
            "Output dimension: 3 \n",
            "Batch size: 16 \n",
            "Using CUDA (FP32C_FP32A) compute method \n",
            "Inference only: 0\n",
            "\n",
            "Dynamic load ENABLED\n",
            "\n",
            "Setting train set\n",
            "input dim :4,Creating dataset with size 100 (nb_batch = 7) ... Done !\n",
            "\n",
            "Setting valid set\n",
            "input dim :4,Creating dataset with size 50 (nb_batch = 4) ... Done !\n",
            "\n",
            "Setting test set\n",
            "input dim :4,Creating dataset with size 50 (nb_batch = 4) ... Done !\n",
            "\n",
            "L:1 - CREATING DENSE LAYER ...\n",
            "      Xavier Normal weight initialization\n",
            "      Input: 5, Nb. Neurons: 8\n",
            "      Activation: LOGI_S6.00_B1.00, Bias: -1.00, dropout rate: 0.00\n",
            "      Nb. weights: 45, Approx layer RAM/VRAM requirement: 0 MB\n",
            "L:2 - CREATING DENSE LAYER ...\n",
            "      Xavier Normal weight initialization\n",
            "      Input: 9, Nb. Neurons: 3\n",
            "      Activation: SMAX, Bias: 0.10, dropout rate: 0.00\n",
            "      Nb. weights: 36, Approx layer RAM/VRAM requirement: 0 MB\n",
            "Fwd :   100 [##############################]    4 /    4 | B.Loss: 0.87002 | B.perf.: 135208 it/s \u001b[?25h\n",
            "              Average forward perf : 65464.22 it/s | Mean Loss: 0.72245\n",
            "\n",
            "   ************  ConfMat  ************   Recall\n",
            "           18 |       0 |       0 |     100.00%\n",
            "            0 |       8 |      10 |      44.44%\n",
            "            0 |       0 |      14 |     100.00%\n",
            "Prec.  100.00%   100.00%    58.33%  Acc  80.00%\n",
            "Saving network for iteration: 100 (mode: 0)\n",
            "Fwd :   200 [##############################]    4 /    4 | B.Loss: 0.72097 | B.perf.: 143062 it/s \u001b[?25h\n",
            "              Average forward perf : 73828.20 it/s | Mean Loss: 0.47654\n",
            "\n",
            "   ************  ConfMat  ************   Recall\n",
            "           18 |       0 |       0 |     100.00%\n",
            "            0 |      11 |       7 |      61.11%\n",
            "            0 |       1 |      13 |      92.86%\n",
            "Prec.  100.00%    91.67%    65.00%  Acc  84.00%\n",
            "Saving network for iteration: 200 (mode: 0)\n",
            "Fwd :   300 [##############################]    4 /    4 | B.Loss: 0.66028 | B.perf.: 136575 it/s \u001b[?25h\n",
            "              Average forward perf : 72388.23 it/s | Mean Loss: 0.37912\n",
            "\n",
            "   ************  ConfMat  ************   Recall\n",
            "           18 |       0 |       0 |     100.00%\n",
            "            0 |      13 |       5 |      72.22%\n",
            "            0 |       1 |      13 |      92.86%\n",
            "Prec.  100.00%    92.86%    72.22%  Acc  88.00%\n",
            "Saving network for iteration: 300 (mode: 0)\n",
            "Fwd :   400 [##############################]    4 /    4 | B.Loss: 0.61305 | B.perf.: 168634 it/s \u001b[?25h\n",
            "              Average forward perf : 78015.78 it/s | Mean Loss: 0.32392\n",
            "\n",
            "   ************  ConfMat  ************   Recall\n",
            "           18 |       0 |       0 |     100.00%\n",
            "            0 |      16 |       2 |      88.89%\n",
            "            0 |       1 |      13 |      92.86%\n",
            "Prec.  100.00%    94.12%    86.67%  Acc  94.00%\n",
            "Saving network for iteration: 400 (mode: 0)\n",
            "Fwd :   500 [##############################]    4 /    4 | B.Loss: 0.56307 | B.perf.: 172414 it/s \u001b[?25h\n",
            "              Average forward perf : 80736.83 it/s | Mean Loss: 0.28597\n",
            "\n",
            "   ************  ConfMat  ************   Recall\n",
            "           18 |       0 |       0 |     100.00%\n",
            "            0 |      16 |       2 |      88.89%\n",
            "            0 |       1 |      13 |      92.86%\n",
            "Prec.  100.00%    94.12%    86.67%  Acc  94.00%\n",
            "Saving network for iteration: 500 (mode: 0)\n",
            "Fwd :   600 [##############################]    4 /    4 | B.Loss: 0.51115 | B.perf.: 176741 it/s \u001b[?25h\n",
            "              Average forward perf : 74703.57 it/s | Mean Loss: 0.25703\n",
            "\n",
            "   ************  ConfMat  ************   Recall\n",
            "           18 |       0 |       0 |     100.00%\n",
            "            0 |      16 |       2 |      88.89%\n",
            "            0 |       1 |      13 |      92.86%\n",
            "Prec.  100.00%    94.12%    86.67%  Acc  94.00%\n",
            "Saving network for iteration: 600 (mode: 0)\n",
            "Fwd :   700 [##############################]    4 /    4 | B.Loss: 0.45561 | B.perf.: 178699 it/s \u001b[?25h\n",
            "              Average forward perf : 81219.45 it/s | Mean Loss: 0.23305\n",
            "\n",
            "   ************  ConfMat  ************   Recall\n",
            "           18 |       0 |       0 |     100.00%\n",
            "            0 |      17 |       1 |      94.44%\n",
            "            0 |       1 |      13 |      92.86%\n",
            "Prec.  100.00%    94.44%    92.86%  Acc  96.00%\n",
            "Saving network for iteration: 700 (mode: 0)\n",
            "Fwd :   800 [##############################]    4 /    4 | B.Loss: 0.40089 | B.perf.: 186567 it/s \u001b[?25h\n",
            "              Average forward perf : 80272.28 it/s | Mean Loss: 0.21256\n",
            "\n",
            "   ************  ConfMat  ************   Recall\n",
            "           18 |       0 |       0 |     100.00%\n",
            "            0 |      17 |       1 |      94.44%\n",
            "            0 |       1 |      13 |      92.86%\n",
            "Prec.  100.00%    94.44%    92.86%  Acc  96.00%\n",
            "Saving network for iteration: 800 (mode: 0)\n",
            "Fwd :   900 [##############################]    4 /    4 | B.Loss: 0.34898 | B.perf.: 182815 it/s \u001b[?25h\n",
            "              Average forward perf : 82922.04 it/s | Mean Loss: 0.19472\n",
            "\n",
            "   ************  ConfMat  ************   Recall\n",
            "           18 |       0 |       0 |     100.00%\n",
            "            0 |      17 |       1 |      94.44%\n",
            "            0 |       1 |      13 |      92.86%\n",
            "Prec.  100.00%    94.44%    92.86%  Acc  96.00%\n",
            "Saving network for iteration: 900 (mode: 0)\n",
            "Fwd :  1000 [##############################]    4 /    4 | B.Loss: 0.30179 | B.perf.: 178508 it/s \u001b[?25h\n",
            "              Average forward perf : 80862.18 it/s | Mean Loss: 0.17906\n",
            "\n",
            "   ************  ConfMat  ************   Recall\n",
            "           18 |       0 |       0 |     100.00%\n",
            "            0 |      17 |       1 |      94.44%\n",
            "            0 |       1 |      13 |      92.86%\n",
            "Prec.  100.00%    94.44%    92.86%  Acc  96.00%\n",
            "Saving network for iteration: 1000 (mode: 0)\n",
            "\n",
            "Total Net. nb weights: 81 \n",
            "Total Network RAM/VRAM usage : 0 MB\n",
            "(without datasets, and prop. to batch_size)\n",
            "\n",
            "     Layer  Type       Forward             Backprop             Cumulated\n",
            "       N     T      [µs]  /  [%]         [µs]  /  [%]         [µs]  /  [%]\n",
            "  -------------------------------------------------------------------\n",
            "       1     D        5.5 / 80.6           1.3 / 30.8           6.8 / 61.5\n",
            "       2     D        1.3 / 19.4           2.9 / 69.2           4.2 / 38.5\n",
            "  -------------------------------------------------------------------\n",
            "   Total              6.8 µs               4.2 µs              11.0 µs       \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "\n",
        "%%shell\n",
        "\n",
        "cd /content/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "import numpy as np\n",
        "import sys, glob\n",
        "\n",
        "sys.path.insert(0,glob.glob('/content/CIANNA/src/build/lib.*/')[-1])\n",
        "import CIANNA as cnn\n",
        "\n",
        "\n",
        "def i_ar(int_list):\n",
        "\treturn np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "\treturn np.array(float_list, dtype=\"float32\")\n",
        "\n",
        "nb_train = 100 # over 150\n",
        "\n",
        "\n",
        "######################### ##########################\n",
        "#          Loading data and pre process\n",
        "######################### ##########################\n",
        "\n",
        "raw_data = np.loadtxt(\"/content/AI_astro_ED_AAIF/codes/data/iris.data\")\n",
        "\n",
        "\n",
        "nb_dat = np.shape(raw_data)[0]\n",
        "in_dim = np.shape(raw_data)[1] - 1\n",
        "out_dim = 3\n",
        "\n",
        "input = np.append(raw_data[:,:in_dim], -1.0*np.ones((nb_dat,1)), axis=1)\n",
        "\n",
        "\n",
        "targ = np.zeros((nb_dat,out_dim))\n",
        "for i in range(0,nb_dat):\n",
        "\ttarg[i,int(raw_data[i,in_dim])] = 1.0\n",
        "\n",
        "\n",
        "input[:,:-1] -= np.mean(input[:,:-1], axis = 0)\n",
        "input[:,:-1] /= np.max(np.abs(input[:,:-1]), axis = 0)\n",
        "\n",
        "\n",
        "# split training and test dataset\n",
        "input_test = input[nb_train:,:]\n",
        "targ_test = targ[nb_train:,:]\n",
        "\n",
        "input = input[0:nb_train,:]\n",
        "targ = targ[0:nb_train,:]\n",
        "\n",
        "\n",
        "cnn.init(in_dim=i_ar([in_dim]), in_nb_ch=1, out_dim=3, \\\n",
        "\t\tbias=-1.0, b_size=16, comp_meth=\"C_CUDA\")\n",
        "\n",
        "cnn.create_dataset(\"TRAIN\", size=nb_train    , input=f_ar(input)     , target=f_ar(targ))\n",
        "cnn.create_dataset(\"VALID\", size=150-nb_train, input=f_ar(input_test), target=f_ar(targ_test))\n",
        "cnn.create_dataset(\"TEST\" , size=150-nb_train, input=f_ar(input_test), target=f_ar(targ_test))\n",
        "\n",
        "\n",
        "cnn.dense(nb_neurons=8, activation=\"LOGI\")\n",
        "cnn.dense(nb_neurons=3, activation=\"SMAX\")\n",
        "\n",
        "cnn.train(nb_iter=1000, learning_rate=0.005, momentum=0.8, confmat=1, control_interv=100, save_every=100, silent=2)\n",
        "\n",
        "cnn.perf_eval()\n",
        "\n",
        "EOF"
      ]
    }
  ]
}
